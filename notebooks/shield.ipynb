{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82f3402",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install pandas\n",
    "!pip install kagglehub\n",
    "!pip install transformers[torch]\n",
    "!pip install matplotlib\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "444099af-1408-4801-9905-eb77e77bc721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "device = (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "\n",
    "NEUTRAL = \"neutral\"\n",
    "BULLYING = \"bullying\"\n",
    "\n",
    "print(f\"device = {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d76ddb47-2877-416c-a16e-847d9f1225db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.12)\n",
      "Path to dataset files: /home/projects/dharel/yaronwin/.cache/kagglehub/datasets/saifulislam7/cyberbullying-and-harassment-detection-using-ml/versions/1\n",
      "table size: 8452\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Types</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ten outside soon doctor shake everyone treatment seat radio land.</th>\n",
       "      <td>Not-Bullying</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my life has come to a standstill and at this point.</th>\n",
       "      <td>Not-Bullying</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl this nigga make me sick to my stomach</th>\n",
       "      <td>Bullying</td>\n",
       "      <td>Ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I wanna fuck you</th>\n",
       "      <td>Bullying</td>\n",
       "      <td>Sexual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oh hey, you should be ashamed of your disgusting self</th>\n",
       "      <td>Not - Bullying</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Haha isn't route running part of the position? People are dumb. But fuck edelman! He just looks like he says</th>\n",
       "      <td>Bullying</td>\n",
       "      <td>Ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Racism is when u select yur white clothes to wash first before the black and colored ones</th>\n",
       "      <td>Bullying</td>\n",
       "      <td>Ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Who are islamists? Those who fully follow the teachings of Muhammed found in the Quran and Hadiths</th>\n",
       "      <td>Bullying</td>\n",
       "      <td>Religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male action movies...ehhhh @That_Damn_Ram Not sexist but female action movies...ehhhh</th>\n",
       "      <td>Bullying</td>\n",
       "      <td>Religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wishing my arena partner was on.</th>\n",
       "      <td>Not Bullying</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Label      Types\n",
       "Text                                                                         \n",
       "Ten outside soon doctor shake everyone treatmen...    Not-Bullying        NaN\n",
       "my life has come to a standstill and at this po...    Not-Bullying        NaN\n",
       "girl this nigga make me sick to my stomach                Bullying  Ethnicity\n",
       "I wanna fuck you                                          Bullying     Sexual\n",
       "Oh hey, you should be ashamed of your disgustin...  Not - Bullying        NaN\n",
       "Haha isn't route running part of the position? ...       Bullying   Ethnicity\n",
       "Racism is when u select yur white clothes to wa...        Bullying  Ethnicity\n",
       "Who are islamists? Those who fully follow the t...        Bullying  Religion \n",
       "Male action movies...ehhhh @That_Damn_Ram Not s...       Bullying   Religion \n",
       "Wishing my arena partner was on.                     Not Bullying         NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the kaggle bullying dataset\n",
    "KAGGLE_TABLE_NAME = \"Approach to Social Media Cyberbullying and Harassment Detection Using Advanced Machine Learning.csv\"\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"saifulislam7/cyberbullying-and-harassment-detection-using-ml\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "kaggle_df = pd.read_csv(path + \"/\" + KAGGLE_TABLE_NAME, index_col=0)\n",
    "print(f\"table size: {len(kaggle_df)}\")\n",
    "kaggle_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7d41b0f-db18-4719-afba-7c94e3db0d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial table size: 8452\n",
      "'clean' table size: 8407\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ten outside soon doctor shake everyone treatme...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my life has come to a standstill and at this p...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>girl this nigga make me sick to my stomach</td>\n",
       "      <td>bullying</td>\n",
       "      <td>Ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I wanna fuck you</td>\n",
       "      <td>bullying</td>\n",
       "      <td>Sexual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh hey, you should be ashamed of your disgusti...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Haha isn't route running part of the position?...</td>\n",
       "      <td>bullying</td>\n",
       "      <td>Ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Racism is when u select yur white clothes to w...</td>\n",
       "      <td>bullying</td>\n",
       "      <td>Ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Who are islamists? Those who fully follow the ...</td>\n",
       "      <td>bullying</td>\n",
       "      <td>Religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Male action movies...ehhhh @That_Damn_Ram Not ...</td>\n",
       "      <td>bullying</td>\n",
       "      <td>Religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wishing my arena partner was on.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I hope this round humbled the girls, they can'...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ha-ha-ha-ha-ha! Islam is against evil</td>\n",
       "      <td>bullying</td>\n",
       "      <td>Religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Thanks to everyone that came out to walk with ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dealing with harassment</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>you not only a nigger, you're a dumb nigger. F...</td>\n",
       "      <td>bullying</td>\n",
       "      <td>Ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Get fucking real dude.</td>\n",
       "      <td>bullying</td>\n",
       "      <td>Sexual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Heh. Fuck 'em WHERE?!?</td>\n",
       "      <td>bullying</td>\n",
       "      <td>Sexual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>You know there are people out there who like b...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Really miss my classmates n schoolmates. See y...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Let's talk about what it means to be a victim</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text     Label      Types\n",
       "0   Ten outside soon doctor shake everyone treatme...   neutral    neutral\n",
       "1   my life has come to a standstill and at this p...   neutral    neutral\n",
       "2          girl this nigga make me sick to my stomach  bullying  Ethnicity\n",
       "3                                    I wanna fuck you  bullying     Sexual\n",
       "4   Oh hey, you should be ashamed of your disgusti...   neutral    neutral\n",
       "5   Haha isn't route running part of the position?...  bullying  Ethnicity\n",
       "6   Racism is when u select yur white clothes to w...  bullying  Ethnicity\n",
       "7   Who are islamists? Those who fully follow the ...  bullying  Religion \n",
       "8   Male action movies...ehhhh @That_Damn_Ram Not ...  bullying  Religion \n",
       "9                    Wishing my arena partner was on.   neutral    neutral\n",
       "10  I hope this round humbled the girls, they can'...   neutral    neutral\n",
       "11             Ha-ha-ha-ha-ha! Islam is against evil   bullying   Religion\n",
       "12  Thanks to everyone that came out to walk with ...   neutral    neutral\n",
       "13                            Dealing with harassment   neutral    neutral\n",
       "14  you not only a nigger, you're a dumb nigger. F...  bullying  Ethnicity\n",
       "15                             Get fucking real dude.  bullying     Sexual\n",
       "16                             Heh. Fuck 'em WHERE?!?  bullying     Sexual\n",
       "17  You know there are people out there who like b...   neutral    neutral\n",
       "18  Really miss my classmates n schoolmates. See y...   neutral    neutral\n",
       "19      Let's talk about what it means to be a victim   neutral    neutral"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arrange the dataset a bit.\n",
    "# Arrange columns names\n",
    "kaggle_df[\"Text1\"] = kaggle_df.index\n",
    "kaggle_df.index = [i for i in range(len(kaggle_df))]\n",
    "kaggle_df = kaggle_df.rename(columns={\"Text1\":\"Text\"})\n",
    "kaggle_df = kaggle_df[[\"Text\", \"Label\", \"Types\"]].reset_index(drop=True)\n",
    "\n",
    "# Arrange labels and types content (make it canonical, avoid duplications)\n",
    "kaggle_df.Types = kaggle_df.Types.apply(lambda x: NEUTRAL if pd.isna(x) else x)\n",
    "kaggle_df.Label = kaggle_df.Label.apply(lambda x: NEUTRAL if not isinstance(x, str) else (NEUTRAL if \"not\" in x.lower() else BULLYING))\n",
    "\n",
    "# Remove mis-match\n",
    "print(f\"initial table size: {len(kaggle_df)}\")\n",
    "kaggle_df = kaggle_df[kaggle_df.apply(lambda x: (x[\"Label\"] == NEUTRAL and x[\"Types\"] == NEUTRAL) or (x[\"Label\"] == BULLYING and x[\"Types\"] != NEUTRAL), axis=1)].reset_index(drop=True)\n",
    "print(f\"'clean' table size: {len(kaggle_df)}\")\n",
    "kaggle_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65e063d1-5def-409a-a883-2e495814d1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table size: 8407\n",
      "binary distribution:\n",
      "\tLabel\n",
      "bullying    4807\n",
      "neutral     3600\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEmCAYAAACOMEBlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAAsTAAALEwEAmpwYAAASdElEQVR4nO3dbbBdVX3H8e8PEJ/Lg1wzNEGDSseiVcA7gNVpKUwj4kOcFik+ZpAxL4qtnVoV+6Ko6BQ7U612qmOmYKODIhUdGLXFKKi1PkACCAJSUgUhookmoKjQBv59cdbVY7iXewP3nkPP+n5m7ty911rnnP+Z3PzOnrXX3idVhSSpD3uMuwBJ0ugY+pLUEUNfkjpi6EtSRwx9SeqIoS9JHVlQ6Ce5Kck1Sa5KsrG17Z9kQ5Ib2+/9WnuSvC/J5iRXJzli6HnWtPE3JlmzNG9JkjSXLGSdfpKbgOmq+tFQ298B26vqrCSnA/tV1ZuTnAD8GXACcBTw3qo6Ksn+wEZgGihgE/Csqtox1+secMABtXLlygf85iSpR5s2bfpRVU3N1rfXg3je1cAxbXs98EXgza39wzX4NPl6kn2THNjGbqiq7QBJNgDHAx+b6wVWrlzJxo0bH0SJktSfJDfP1bfQOf0CPpdkU5K1rW1ZVd3Wtn8ALGvby4Fbhh57a2ubq12SNCILPdJ/blVtSfJ4YEOSbw93VlUlWZT7ObQPlbUAT3jCExbjKSVJzYKO9KtqS/u9FfgUcCTwwzZtQ/u9tQ3fAhw09PAVrW2u9l1fa11VTVfV9NTUrFNSkqQHaN7QT/LoJI+d2QZWAd8CLgJmVuCsAS5s2xcBr26reI4G7mjTQBcDq5Ls11b6rGptkqQRWcj0zjLgU0lmxn+0qv49yeXA+UlOBW4GTmrjP8tg5c5m4OfAKQBVtT3JmcDlbdzbZ07qSpJGY0FLNsdlenq6XL0jSbsnyaaqmp6tzytyJakjhr4kdcTQl6SOPJgrctWsPP0z4y5hotx01gvGXYI0sTzSl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR1ZcOgn2TPJlUk+3fYPTvKNJJuTfDzJ3q394W1/c+tfOfQcb2ntNyR53qK/G0nS/dqdI/3XA9cP7b8LeE9VPQXYAZza2k8FdrT297RxJDkUOBl4GnA88P4kez648iVJu2NBoZ9kBfAC4J/bfoBjgU+0IeuBl7Tt1W2f1n9cG78aOK+q7q6q7wKbgSMX4T1IkhZooUf6/wC8Cbi37T8OuL2qdrb9W4HlbXs5cAtA67+jjf9l+yyPkSSNwLyhn+SFwNaq2jSCekiyNsnGJBu3bds2ipeUpG4s5Ej/OcCLk9wEnMdgWue9wL5J9mpjVgBb2vYW4CCA1r8P8OPh9lke80tVta6qpqtqempqarffkCRpbvOGflW9papWVNVKBidiL6mqVwCXAie2YWuAC9v2RW2f1n9JVVVrP7mt7jkYOAS4bNHeiSRpXnvNP2RObwbOS/IO4Erg7NZ+NvCRJJuB7Qw+KKiqa5OcD1wH7AROq6p7HsTrS5J2026FflV9Efhi2/4Os6y+qaq7gJfO8fh3Au/c3SIlSYvDK3IlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1JEHc5dNSf8PrDz9M+MuYWLcdNYLxl3Cg+aRviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JH5g39JI9IclmSbya5NsnbWvvBSb6RZHOSjyfZu7U/vO1vbv0rh57rLa39hiTPW7J3JUma1UKO9O8Gjq2qZwKHAccnORp4F/CeqnoKsAM4tY0/FdjR2t/TxpHkUOBk4GnA8cD7k+y5iO9FkjSPeUO/Bu5suw9rPwUcC3yita8HXtK2V7d9Wv9xSdLaz6uqu6vqu8Bm4MjFeBOSpIVZ0Jx+kj2TXAVsBTYA/w3cXlU725BbgeVtezlwC0DrvwN43HD7LI+RJI3AgkK/qu6pqsOAFQyOzp+6VAUlWZtkY5KN27ZtW6qXkaQu7dbqnaq6HbgUeDawb5K9WtcKYEvb3gIcBND69wF+PNw+y2OGX2NdVU1X1fTU1NTulCdJmsdCVu9MJdm3bT8S+EPgegbhf2Ibtga4sG1f1PZp/ZdUVbX2k9vqnoOBQ4DLFul9SJIWYK/5h3AgsL6ttNkDOL+qPp3kOuC8JO8ArgTObuPPBj6SZDOwncGKHarq2iTnA9cBO4HTquqexX07kqT7M2/oV9XVwOGztH+HWVbfVNVdwEvneK53Au/c/TIlSYvBK3IlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdWTe0E9yUJJLk1yX5Nokr2/t+yfZkOTG9nu/1p4k70uyOcnVSY4Yeq41bfyNSdYs3duSJM1mIUf6O4E3VNWhwNHAaUkOBU4HvlBVhwBfaPsAzwcOaT9rgQ/A4EMCOAM4CjgSOGPmg0KSNBrzhn5V3VZVV7TtnwLXA8uB1cD6Nmw98JK2vRr4cA18Hdg3yYHA84ANVbW9qnYAG4DjF/PNSJLu327N6SdZCRwOfANYVlW3ta4fAMva9nLglqGH3dra5mqXJI3IgkM/yWOAC4C/qKqfDPdVVQG1GAUlWZtkY5KN27ZtW4ynlCQ1Cwr9JA9jEPjnVtUnW/MP27QN7ffW1r4FOGjo4Sta21ztv6aq1lXVdFVNT01N7c57kSTNYyGrdwKcDVxfVe8e6roImFmBswa4cKj91W0Vz9HAHW0a6GJgVZL92gncVa1NkjQiey1gzHOAVwHXJLmqtf01cBZwfpJTgZuBk1rfZ4ETgM3Az4FTAKpqe5IzgcvbuLdX1fbFeBOSpIWZN/Sr6itA5ug+bpbxBZw2x3OdA5yzOwVKkhaPV+RKUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdmTf0k5yTZGuSbw217Z9kQ5Ib2+/9WnuSvC/J5iRXJzli6DFr2vgbk6xZmrcjSbo/CznS/xfg+F3aTge+UFWHAF9o+wDPBw5pP2uBD8DgQwI4AzgKOBI4Y+aDQpI0OvOGflV9Gdi+S/NqYH3bXg+8ZKj9wzXwdWDfJAcCzwM2VNX2qtoBbOC+HySSpCX2QOf0l1XVbW37B8Cytr0cuGVo3K2tba72+0iyNsnGJBu3bdv2AMuTJM3mQZ/IraoCahFqmXm+dVU1XVXTU1NTi/W0kiQeeOj/sE3b0H5vbe1bgIOGxq1obXO1S5JG6IGG/kXAzAqcNcCFQ+2vbqt4jgbuaNNAFwOrkuzXTuCuam2SpBHaa74BST4GHAMckORWBqtwzgLOT3IqcDNwUhv+WeAEYDPwc+AUgKranuRM4PI27u1VtevJYUnSEps39KvqZXN0HTfL2AJOm+N5zgHO2a3qJEmLyityJakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHVk5KGf5PgkNyTZnOT0Ub++JPVspKGfZE/gn4DnA4cCL0ty6ChrkKSejfpI/0hgc1V9p6r+BzgPWD3iGiSpW3uN+PWWA7cM7d8KHDU8IMlaYG3bvTPJDSOqrQcHAD8adxHzybvGXYHGwL/NxfXEuTpGHfrzqqp1wLpx1zGJkmysqulx1yHtyr/N0Rn19M4W4KCh/RWtTZI0AqMO/cuBQ5IcnGRv4GTgohHXIEndGun0TlXtTPI64GJgT+Ccqrp2lDV0zmkzPVT5tzkiqapx1yBJGhGvyJWkjhj6ktQRQ1+SOmLoS1JHHnIXZ2lxJfkpsOvZ+juAjcAbquo7o69KPZvjbxIgQFXVb4y4pK4Y+pPvHxjc7uKjDP5TnQw8GbgCOAc4ZlyFqU9V9dhx19Azl2xOuCTfrKpn7tJ2VVUdNlufNGpJHg88Yma/qr43xnImnnP6k+/nSU5Kskf7OQm4q/X5ia+xSfLiJDcC3wW+BNwE/NtYi+qAoT/5XgG8CtgK/LBtvzLJI4HXjbMwde9M4Gjgv6rqYOA44OvjLWnyOb0jaSxm7qyZ5JvA4VV1r1OOS88TuRMuyRTwWmAlQ//eVfWacdUkNbcneQzwZeDcJFuBn425ponnkf6ES/JV4D+ATcA9M+1VdcHYipKAJI8GfsFgmvkVwD7AuVX147EWNuEM/Qk3s1Jn3HVIw9r3ZX++qv5g3LX0xhO5k+/TSU4YdxHSsKq6B7g3yT7jrqU3HulPuHb146OBu4H/xase9RCR5ELgcGADQ3P5VfXnYyuqA57InXBe/aiHsE+2n2EehS4xQ39CJXlqVX07yRGz9VfVFaOuSdrFvlX13uGGJK8fVzG9cHpnQiVZV1Vrk1w6S3dV1bEjL0oakuSKqjpil7Yrq+rwcdXUA0Nf0kgleRnwcuC5DJYTz3gscG9VHTeWwjrh9M6ES7IJOBv4WFXtGHc9EvBV4DbgAODvh9p/Clw9loo64pH+hEvyFOAU4E8Y3EP/Q8Dnyn94qUuGfieS7AG8EPgAgytzPwS8t6q2j7UwdWuXL1PZG3gY8DOXEy8tp3c6kOQZDI72TwAuAM5lMJ96CXDY+CpTz4aXEycJsJrBXTe1hDzSn3BtTv92BvP6F1TV3UN9n6yqPxpXbdKuXL2z9Az9CZfkSX4Prh6KkgwfcOwBTAO/X1XPHlNJXXB6Z0Il+cuh7fv0V9W7R1qQdF8vGtreyeCbs1aPp5R+GPqTy9sv6CGtqk4Zdw09cnpH0lgk+S0Gq8mWVdXT24KDF1fVO8Zc2kQz9CdUkvfdX793MtS4JfkS8EbggzMnb5N8q6qePt7KJpvTO5Nr07gLkObxqKq6bJdzTjvHVUwvDP0JVVXrx12DNI8fJXky7QKtJCcyuD2DlpDTOxOu3WXzPv/I3mVT45bkScA64HeBHcB3gVdU1c1jLWzCGfoTLsmzhnYfAfwxsLOq3jSmkiQAkjwcOBFYCewP/ITBbb/fPs66Jp3TOxOuqnad2//PJJeNpRjp113I4GrxK4Dvj7eUfhj6Ey7J/kO7M1c9+mXUeihYUVXHj7uI3hj6k28Tv5rTn7nq8dSxVSP9yleT/E5VXTPuQnrinP6ES/JI4E8Z3FWzGHxT0Qeq6q6xFqbuJbkOeAqDE7h3A2Ewp/+MsRY24Qz9CZfkfAYnyM5tTS9n8IXULx1fVRIkeeJs7a7eWVqG/oRLcl1VHTpfm6Q+7DHuArTkrkjyyy+mSHIUg69NlNQhT+ROqCTXMJjDfxiDE2bfa/tPBL49ztokjY/TOxNqrvnSGc6bSn0y9CWpI87pS1JHDH1J6oihLwFJ7tyNsW9N8ldL9fzSUjL0Jakjhr40hyQvSvKNJFcm+XySZUPdz0zytSQ3Jnnt0GPemOTyJFcnedsYypbul6Evze0rwNHt+1vPA4a/g+AZwLHAs4G/SfKbSVYBhwBHAocBz0rye6MtWbp/XpwlzW0F8PEkBwJ7M7gx2IwLq+oXwC/at5MdyeCmdquAK9uYxzD4EPjy6EqW7p+hL83tH4F3V9VFSY4B3jrUt+sFLsXgLpF/W1UfHEl10gPg9I40t32ALW17zS59q5M8IsnjgGOAy4GLgdckeQxAkuVJHj+qYqWF8EhfGnhUkluH9t/N4Mj+X5PsAC4BDh7qvxq4FDgAOLOqvg98P8lvA19LAnAn8Epg69KXLy2Mt2GQpI44vSNJHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqyP8BRZnng12/W3oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check binary distribution\n",
    "print(f\"table size: {len(kaggle_df)}\")\n",
    "print(f\"binary distribution:\\n\\t{kaggle_df.Label.value_counts()}\")\n",
    "num_lables = sum([x for x in dict(kaggle_df.Label.value_counts()).values()])\n",
    "kaggle_df.Label.value_counts().plot(kind=\"bar\")\n",
    "# Verify adequateness\n",
    "assert num_lables  == len(kaggle_df), f\"sizes miss match - there are {num_lables} labels, while the table size is {len(kaggle_df)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa5e171d-f71a-4613-ba81-b5476d3de69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi class distribution:\n",
      "\tTypes\n",
      "neutral        3600\n",
      "Sexual          984\n",
      "Troll           948\n",
      "Political       734\n",
      "Vocational      667\n",
      "Religion        642\n",
      "Threat          192\n",
      "Ethnicity       169\n",
      "Threats         157\n",
      "Vocational       75\n",
      "Religion         48\n",
      "Religon          45\n",
      "Sexual           36\n",
      "Ethnicity        31\n",
      "Threats          23\n",
      "Political        20\n",
      "Religious        10\n",
      "Troll             7\n",
      "sexual            6\n",
      "Racism            4\n",
      "political         3\n",
      "Vocation          2\n",
      "Saxual            2\n",
      "Ethnically        1\n",
      "Threat            1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check multi class distribution\n",
    "print(f\"multi class distribution:\\n\\t{kaggle_df.Types.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9ab15dc-2bd2-41e9-9228-d37bc35ccf13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed multi class distribution:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fix class names\n",
    "kaggle_df.Types = kaggle_df.Types.apply(lambda x: x.strip())\n",
    "\n",
    "# Convert into canonical names.\n",
    "# Notice that 'racism' is converted into 'ethnicity', as there are only 4 cases\n",
    "# of racism, and due to the proximity between racism and ethnicity.\n",
    "conversion = {NEUTRAL: NEUTRAL, \"Sexual\":\"sexual\",\n",
    "              \"Troll\":\"troll\", \"Political\":\"political\", \"Vocational\":\"vocational\", \n",
    "              \"Religion\":\"religion\", \"Ethnicity\":\"ethnicity\", \"Threat\":\"threat\", \"Threats\":\"threat\",\n",
    "              \"Religon\":\"religion\", \"Religious\":\"religion\", \"sexual\":\"sexual\", \"Racism\":\"ethnicity\",\n",
    "              \"political\":\"political\", \"Vocation\":\"vocational\", \"Saxual\":\"sexual\", \"Ethnically\":\"ethnicity\"}\n",
    "kaggle_df.Types = kaggle_df.Types.map(conversion)\n",
    "print(\"fixed multi class distribution:\\n\")\n",
    "kaggle_df.Types.value_counts().plot(kind=\"bar\")\n",
    "num_lables = sum([x for x in dict(kaggle_df.Types.value_counts()).values()])\n",
    "\n",
    "# Verify adequatenesskaggle_df.Types.value_counts()\n",
    "assert num_lables  == len(kaggle_df), f\"sizes miss match - there are {num_lables} labels, while the table size is {len(kaggle_df)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3c41b53-7ec1-4312-8293-d8ca31291977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial table size: 8407\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ten outside soon doctor shake everyone treatme...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my life has come to a standstill and at this p...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>girl this nigga make me sick to my stomach</td>\n",
       "      <td>bullying</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i wanna fuck you</td>\n",
       "      <td>bullying</td>\n",
       "      <td>sexual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oh hey you should be ashamed of your disgustin...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>haha isn ' t route running part of the positio...</td>\n",
       "      <td>bullying</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>racism is when u select yur white clothes to w...</td>\n",
       "      <td>bullying</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>who are islamists ? those who fully follow the...</td>\n",
       "      <td>bullying</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>male action movies ... ehhhh @ that damn ram n...</td>\n",
       "      <td>bullying</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wishing my arena partner was on .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>i hope this round humbled the girls they can '...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ha ha ha ha ha ! islam is against evil</td>\n",
       "      <td>bullying</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>thanks to everyone that came out to walk with ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dealing with harassment</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>you not only a nigger you ' re a dumb nigger ....</td>\n",
       "      <td>bullying</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>get fucking real dude .</td>\n",
       "      <td>bullying</td>\n",
       "      <td>sexual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>heh . fuck ' em where ? ! ?</td>\n",
       "      <td>bullying</td>\n",
       "      <td>sexual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>you know there are people out there who like b...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>really miss my classmates n schoolmates . see ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>let ' s talk about what it means to be a victim</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text     Label      Types\n",
       "0   ten outside soon doctor shake everyone treatme...   neutral    neutral\n",
       "1   my life has come to a standstill and at this p...   neutral    neutral\n",
       "2          girl this nigga make me sick to my stomach  bullying  ethnicity\n",
       "3                                    i wanna fuck you  bullying     sexual\n",
       "4   oh hey you should be ashamed of your disgustin...   neutral    neutral\n",
       "5   haha isn ' t route running part of the positio...  bullying  ethnicity\n",
       "6   racism is when u select yur white clothes to w...  bullying  ethnicity\n",
       "7   who are islamists ? those who fully follow the...  bullying   religion\n",
       "8   male action movies ... ehhhh @ that damn ram n...  bullying   religion\n",
       "9                   wishing my arena partner was on .   neutral    neutral\n",
       "10  i hope this round humbled the girls they can '...   neutral    neutral\n",
       "11             ha ha ha ha ha ! islam is against evil  bullying   religion\n",
       "12  thanks to everyone that came out to walk with ...   neutral    neutral\n",
       "13                            dealing with harassment   neutral    neutral\n",
       "14  you not only a nigger you ' re a dumb nigger ....  bullying  ethnicity\n",
       "15                            get fucking real dude .  bullying     sexual\n",
       "16                        heh . fuck ' em where ? ! ?  bullying     sexual\n",
       "17  you know there are people out there who like b...   neutral    neutral\n",
       "18  really miss my classmates n schoolmates . see ...   neutral    neutral\n",
       "19    let ' s talk about what it means to be a victim   neutral    neutral"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the texts.\n",
    "# The normalization consists of:\n",
    "# - break the text into textual tokens (e.g. for seperating puctuation signs from words [did you? => did you ?])\n",
    "# - add space between any alphapetic word to non alphabetic sign (e.g. ha-ha-ha => ha - ha - ha)\n",
    "# - lower case the texts (for reducing sparsity)\n",
    "# - remove redundant signs (e.g. '-' and '_' are redundant, while '@' and '!' are not, in this context)\n",
    "\n",
    "# I kept the normalization simple and minimal, after some preliminary examination of the data\n",
    "REMOVE_NONE_ALPHABET = r\"[^a-zA-Z0-9\\'\\s\\?!\\.$#@]\"\n",
    "ALP_NON_ALP = r'([A-Za-z])([^A-Za-z])'\n",
    "NON_ALP_ALP = r'([^A-Za-z])([A-Za-z])'\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import re\n",
    "import itertools\n",
    "print(f\"initial table size: {len(kaggle_df)}\")\n",
    "\n",
    "tweeter_tokenizer = TweetTokenizer()\n",
    "def add_space(x: str) -> str:\n",
    "    s = re.sub(ALP_NON_ALP, r'\\1 \\2', x)\n",
    "    s = re.sub(NON_ALP_ALP, r\"\\1 \\2\", s)\n",
    "    return s\n",
    "\n",
    "def text_processing(text: str) -> str:\n",
    "    tokens = tweeter_tokenizer.tokenize(text)\n",
    "    tokens = [add_space(t).lower() for t in tokens]\n",
    "    tokens = [re.sub(REMOVE_NONE_ALPHABET, \"\", t).strip().split() for t in tokens]\n",
    "    tokens = list(itertools.chain(*tokens))\n",
    "    return \" \".join(tokens)\n",
    "kaggle_df.Text = kaggle_df.Text.apply(lambda x: text_processing(x))\n",
    "kaggle_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "331e39a7-c668-4b6a-84d5-4f70b6d9736e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#train items = 6767, #val items = 589, #test items = 1051\n",
      "labels distribution of the test set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Types'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split the dataset, into train, test and eval.\n",
    "# Use seed for reproducibility purpose.\n",
    "from sklearn.model_selection import train_test_split\n",
    "trainval_df, test_df = train_test_split(kaggle_df, test_size=0.125, random_state=42, stratify=kaggle_df.Types)\n",
    "train_df, eval_df = train_test_split(trainval_df, test_size=0.080, random_state=42, stratify=trainval_df.Types)\n",
    "print(f\"#train items = {len(train_df)}, #val items = {len(eval_df)}, #test items = {len(test_df)}\")\n",
    "print(\"labels distribution of the test set:\")\n",
    "test_df.Types.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2071f07-0636-4517-b16b-4f9bf573e38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The phrases with the highest tfidf scores of each class:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>political</th>\n",
       "      <th>religion</th>\n",
       "      <th>sexual</th>\n",
       "      <th>threat</th>\n",
       "      <th>troll</th>\n",
       "      <th>vocational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nigga</td>\n",
       "      <td>political</td>\n",
       "      <td>religious</td>\n",
       "      <td>sexual</td>\n",
       "      <td>police</td>\n",
       "      <td>post</td>\n",
       "      <td>job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nigger</td>\n",
       "      <td>public</td>\n",
       "      <td>religion</td>\n",
       "      <td>ll</td>\n",
       "      <td>received</td>\n",
       "      <td>comedy</td>\n",
       "      <td>ll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>white</td>\n",
       "      <td>political leaders</td>\n",
       "      <td>critical</td>\n",
       "      <td>want</td>\n",
       "      <td>threat</td>\n",
       "      <td>instagram</td>\n",
       "      <td>work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>niggers</td>\n",
       "      <td>undermines</td>\n",
       "      <td>historical</td>\n",
       "      <td>sex</td>\n",
       "      <td>kidnappers</td>\n",
       "      <td>humor</td>\n",
       "      <td>economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>country</td>\n",
       "      <td>leaders</td>\n",
       "      <td>religious leaders</td>\n",
       "      <td>body</td>\n",
       "      <td>railway</td>\n",
       "      <td>laughter</td>\n",
       "      <td>just</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dumb</td>\n",
       "      <td>government</td>\n",
       "      <td>religious institutions</td>\n",
       "      <td>sexy</td>\n",
       "      <td>threat kill</td>\n",
       "      <td>like</td>\n",
       "      <td>stress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fuck</td>\n",
       "      <td>erosion</td>\n",
       "      <td>concerned</td>\n",
       "      <td>hot</td>\n",
       "      <td>main</td>\n",
       "      <td>laugh</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>people</td>\n",
       "      <td>exploitation</td>\n",
       "      <td>islam</td>\n",
       "      <td>fuck</td>\n",
       "      <td>stations</td>\n",
       "      <td>posts</td>\n",
       "      <td>work life balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>asking</td>\n",
       "      <td>neglect</td>\n",
       "      <td>muslims</td>\n",
       "      <td>unwanted</td>\n",
       "      <td>railway stations</td>\n",
       "      <td>reason</td>\n",
       "      <td>life balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>asking questions</td>\n",
       "      <td>national</td>\n",
       "      <td>skeptical</td>\n",
       "      <td>make</td>\n",
       "      <td>prosecution</td>\n",
       "      <td>hero</td>\n",
       "      <td>workers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>law</td>\n",
       "      <td>economic</td>\n",
       "      <td>institutions</td>\n",
       "      <td>night</td>\n",
       "      <td>kill</td>\n",
       "      <td>just</td>\n",
       "      <td>gig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>black</td>\n",
       "      <td>suppression</td>\n",
       "      <td>leaders</td>\n",
       "      <td>like</td>\n",
       "      <td>terrorist</td>\n",
       "      <td>account</td>\n",
       "      <td>work life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>called</td>\n",
       "      <td>abuse</td>\n",
       "      <td>teachings</td>\n",
       "      <td>love</td>\n",
       "      <td>witness</td>\n",
       "      <td>tiktok</td>\n",
       "      <td>gig economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>war</td>\n",
       "      <td>threatens</td>\n",
       "      <td>concerned historical</td>\n",
       "      <td>girl</td>\n",
       "      <td>police terrorist</td>\n",
       "      <td>sense humor</td>\n",
       "      <td>market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>racism</td>\n",
       "      <td>manipulation</td>\n",
       "      <td>claims</td>\n",
       "      <td>boobs</td>\n",
       "      <td>nuclear weapons</td>\n",
       "      <td>videos</td>\n",
       "      <td>difficult</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ethnicity          political                religion    sexual  \\\n",
       "0              nigga          political               religious    sexual   \n",
       "1             nigger             public                religion        ll   \n",
       "2              white  political leaders                critical      want   \n",
       "3            niggers         undermines              historical       sex   \n",
       "4            country            leaders       religious leaders      body   \n",
       "5               dumb         government  religious institutions      sexy   \n",
       "6               fuck            erosion               concerned       hot   \n",
       "7             people       exploitation                   islam      fuck   \n",
       "8             asking            neglect                 muslims  unwanted   \n",
       "9   asking questions           national               skeptical      make   \n",
       "10               law           economic            institutions     night   \n",
       "11             black        suppression                 leaders      like   \n",
       "12            called              abuse               teachings      love   \n",
       "13               war          threatens    concerned historical      girl   \n",
       "14            racism       manipulation                  claims     boobs   \n",
       "\n",
       "              threat        troll         vocational  \n",
       "0             police         post                job  \n",
       "1           received       comedy                 ll  \n",
       "2             threat    instagram               work  \n",
       "3         kidnappers        humor            economy  \n",
       "4            railway     laughter               just  \n",
       "5        threat kill         like             stress  \n",
       "6               main        laugh             health  \n",
       "7           stations        posts  work life balance  \n",
       "8   railway stations       reason       life balance  \n",
       "9        prosecution         hero            workers  \n",
       "10              kill         just                gig  \n",
       "11         terrorist      account          work life  \n",
       "12           witness       tiktok        gig economy  \n",
       "13  police terrorist  sense humor             market  \n",
       "14   nuclear weapons       videos          difficult  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some text distribution exploration\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3), max_features=2500, stop_words=\"english\")\n",
    "\n",
    "# Concatenate the texts of each class.\n",
    "classese_df = kaggle_df.groupby(\"Types\").agg({\"Text\":\" \".join, \"Label\":\"first\", \"Types\":\"first\"}).reset_index(drop=True)\n",
    "\n",
    "PHRASE = \"phrase\"\n",
    "tfidf_mat = vectorizer.fit_transform(classese_df.Text.tolist())\n",
    "tfidf_mat = tfidf_mat.todense()\n",
    "labels = classese_df.Types.tolist()\n",
    "phrases = vectorizer.get_feature_names_out().tolist()\n",
    "table = {label:[] for label in labels}\n",
    "for i in range(len(labels)):\n",
    "    table[labels[i]] = [tfidf_mat[i,j] for j in range(len(phrases))]\n",
    "tfidf_df = pd.DataFrame(table, columns=labels)\n",
    "tfidf_df[PHRASE] = phrases\n",
    "tfidf_df = tfidf_df[[PHRASE] + labels].reset_index(drop=True)\n",
    "\n",
    "def get_evident_phrases(input_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    labels = [x for x in input_df.columns.tolist()[1:] if x != NEUTRAL]\n",
    "    sorted_table = {label:[] for label in labels}\n",
    "    for label in labels:\n",
    "        sorted_df = input_df.sort_values(by=label, axis=0, ascending=False)\n",
    "        sorted_table[label] = sorted_df[PHRASE].tolist()[:15]\n",
    "    return pd.DataFrame(sorted_table)\n",
    "    \n",
    "tfidf_df = get_evident_phrases(tfidf_df)\n",
    "print(\"The phrases with the highest tfidf scores of each class:\\n\")\n",
    "tfidf_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3baddef9-bbd5-43a9-b994-4a0bbf3aac3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Classification:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.95      0.82      0.88       450\n",
      "    bullying       0.88      0.97      0.92       601\n",
      "\n",
      "    accuracy                           0.91      1051\n",
      "   macro avg       0.91      0.90      0.90      1051\n",
      "weighted avg       0.91      0.91      0.90      1051\n",
      "\n",
      "\n",
      "\n",
      "Multi Class Classification:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.77      0.95      0.85       450\n",
      "      sexual       0.82      0.80      0.81       128\n",
      "       troll       0.82      0.67      0.74       119\n",
      "   political       0.97      0.94      0.95        95\n",
      "    religion       0.96      0.85      0.90        93\n",
      "  vocational       0.76      0.51      0.61        93\n",
      "      threat       0.96      0.47      0.63        47\n",
      "   ethnicity       0.92      0.46      0.62        26\n",
      "\n",
      "    accuracy                           0.82      1051\n",
      "   macro avg       0.87      0.71      0.76      1051\n",
      "weighted avg       0.83      0.82      0.81      1051\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We saw above that some of the classes are characterized by pretty evident phrases.\n",
    "# Let's start with a simple baseline.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3), max_features=7500, stop_words=\"english\")\n",
    "X_Train = vectorizer.fit_transform(trainval_df.Text.tolist())\n",
    "X_Train = np.asarray(X_Train.todense())\n",
    "\n",
    "X_Test = vectorizer.transform(test_df.Text.tolist())\n",
    "X_Test = np.asarray(X_Test.todense())\n",
    "\n",
    "# Let's start with binary classification.\n",
    "y_train = trainval_df.Label.map({NEUTRAL:0, BULLYING:1}).values\n",
    "y_test = test_df.Label.map({NEUTRAL:0, BULLYING:1}).values\n",
    "\n",
    "lr = LogisticRegression(random_state=42, solver='liblinear', penalty='l2')\n",
    "model = lr.fit(X_Train, y_train)\n",
    "y_preds = model.predict(X_Test)\n",
    "print(f\"Binary Classification:\\n{metrics.classification_report(y_true=y_test, y_pred=y_preds, target_names=[NEUTRAL, BULLYING])}\")\n",
    "\n",
    "# Now check fine grained classification.\n",
    "y_train = trainval_df.Label.map({NEUTRAL:0, BULLYING:1}).values\n",
    "y_test = test_df.Label.map({NEUTRAL:0, BULLYING:1}).values\n",
    "\n",
    "labels = [x for x in dict(trainval_df.Types.value_counts())]\n",
    "label2index = {x:i for x,i in zip(labels, range(len(labels)))}\n",
    "y_train = trainval_df.Types.map(label2index).values\n",
    "y_test = test_df.Types.map(label2index).values\n",
    "model = lr.fit(X_Train, y_train)\n",
    "y_preds = model.predict(X_Test)\n",
    "print(f\"\\n\\nMulti Class Classification:\\n{metrics.classification_report(y_true=y_test, y_pred=y_preds, target_names=[x for x in label2index])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d964b4bc-1597-4a7e-999c-ff1e1b9a704c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Multi Class Classification, single pass, only bullying:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      sexual       0.73      0.93      0.82       128\n",
      "       troll       0.83      0.85      0.84       119\n",
      "   political       0.97      0.97      0.97        95\n",
      "    religion       0.94      0.90      0.92        93\n",
      "  vocational       0.72      0.71      0.71        93\n",
      "      threat       0.96      0.51      0.67        47\n",
      "   ethnicity       0.87      0.50      0.63        26\n",
      "\n",
      "    accuracy                           0.83       601\n",
      "   macro avg       0.86      0.77      0.79       601\n",
      "weighted avg       0.84      0.83      0.83       601\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The assignment defintion implies, that pipeline classification may be better than a\n",
    "# single multi-class classification phase (\"If harassment is detected, classify it into categories...\")\n",
    "# Let's use this simple baseline for checking whether pipeline classification indeed outperforms \n",
    "# the single pass classification.\n",
    "\n",
    "# Remove all neutral items, both from the train set and from the test set.\n",
    "sub_train_df = trainval_df[trainval_df.Label == BULLYING].reset_index(drop=True)\n",
    "sub_test_df = test_df[test_df.Label == BULLYING].reset_index(drop=True)\n",
    "labels = [x for x in dict(sub_train_df.Types.value_counts())]\n",
    "label2index = {x:i for x,i in zip(labels, range(len(labels)))}\n",
    "\n",
    "X_Train = vectorizer.fit_transform(sub_train_df.Text.tolist())\n",
    "X_Train = np.asarray(X_Train.todense())\n",
    "\n",
    "X_Test = vectorizer.transform(sub_test_df.Text.tolist())\n",
    "X_Test = np.asarray(X_Test.todense())\n",
    "\n",
    "y_train = sub_train_df.Types.map(label2index).values\n",
    "y_test = sub_test_df.Types.map(label2index).values\n",
    "model = lr.fit(X_Train, y_train)\n",
    "y_preds = model.predict(X_Test)\n",
    "print(f\"\\n\\nMulti Class Classification, single pass, only bullying:\\n{metrics.classification_report(y_true=y_test, y_pred=y_preds, target_names=[x for x in label2index])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74d171ac-8393-43f8-b049-10f2ddec646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is indeed some improvement in performance (e.g. macro F1: 76% -> 79%, vocational: 61% -> 71%),\n",
    "# but overall it's a modest rather than dramatic improvement, and some of it will be surely lost in pipeline\n",
    "# So I will be content, for this task, with the single phase classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3d0ccf5-97f5-4465-bad4-9c682eb8dc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done establish transformer objects\n"
     ]
    }
   ],
   "source": [
    "# Transformer classification objects\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import RobertaForSequenceClassification\n",
    "\n",
    "# The classifier\n",
    "class RobertaClassifier(nn.Module):\n",
    "    def __init__(self, num_labels: int, model: RobertaForSequenceClassification):\n",
    "        super(RobertaClassifier, self).__init__()\n",
    "        self.roberta = model.roberta\n",
    "        self.dense = model.classifier.dense\n",
    "        self.fc = nn.Linear(model.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(\n",
    "        self, input_ids: torch.Tensor, attention_mask: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        x = self.roberta(input_ids, attention_mask)\n",
    "        x = self.dense(x.last_hidden_state)\n",
    "        logits = self.fc(x[:, 0, :])\n",
    "        return logits\n",
    "\n",
    "ATTENTION_MASK = \"attention_mask\"\n",
    "INPUT_IDS = \"input_ids\"\n",
    "LABEL = \"label\"\n",
    "TEXT = \"Text\"\n",
    "\n",
    "# Dataset\n",
    "class RobertaDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, target_field: str, label2index: dict, tokenizer: RobertaTokenizer):\n",
    "        super(RobertaDataset, self).__init__()\n",
    "        tokenized_texts = [\n",
    "            tokenizer(\n",
    "                text,\n",
    "                padding=\"max_length\",\n",
    "                max_length=tokenizer.model_max_length,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            for text in df[TEXT]\n",
    "        ]\n",
    "        self.labels = df[target_field].map(label2index).values.tolist()\n",
    "        self.tokens = [item[INPUT_IDS].squeeze() for item in tokenized_texts]\n",
    "        self.masks = [item[ATTENTION_MASK].squeeze() for item in tokenized_texts]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        tokens = self.tokens[index]\n",
    "        mask = self.masks[index]\n",
    "        label = torch.tensor(self.labels[index])\n",
    "        return tokens, mask, label\n",
    "\n",
    "PREDICTIONS = \"predictions\"\n",
    "TRUES = \"trues\"\n",
    "DURATION = \"duration\"\n",
    "ACCURACY = \"accuracy\"\n",
    "MACRO_F1 = \"macro_f1\"\n",
    "\n",
    "def predict(model: nn.Module, dl: DataLoader) -> dict:\n",
    "    y_preds = []\n",
    "    y_trues = []\n",
    "    start_time = time.time()\n",
    "    model = model.eval()\n",
    "    for batch in dl:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = (\n",
    "            input_ids.to(device),\n",
    "            attention_mask.to(device),\n",
    "            labels.to(device),\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        y_preds += torch.argmax(logits, dim=1).tolist()\n",
    "        y_trues += labels.tolist()\n",
    "\n",
    "    duration = time.time() - start_time\n",
    "    acc = metrics.accuracy_score(y_true=y_trues, y_pred=y_preds)\n",
    "    f1 = metrics.f1_score(y_true=y_trues, y_pred=y_preds, average=\"macro\")\n",
    "    return {\n",
    "        DURATION: duration,\n",
    "        ACCURACY: acc,\n",
    "        MACRO_F1: f1,\n",
    "        PREDICTIONS: y_preds,\n",
    "        TRUES: y_trues\n",
    "    }\n",
    "\n",
    "LEARNIN_RATE = 1e-5\n",
    "MAX_EPOCHS = 12\n",
    "MODEL_NAME = \"roberta-large\"\n",
    "BETA_ONE = 0.0\n",
    "BETA_TWO = 0.98\n",
    "ADAM_EPS = 0.00000001\n",
    "BATCH_SIZE = 32\n",
    "EVAL = \"eval\"\n",
    "TRAIN = \"train\"\n",
    "TEST = \"test\"\n",
    "EARLY_STOP_PATIENCE = 3\n",
    "EVAL_TRAIN_FRACTION = 0.075\n",
    "\n",
    "@dataclass\n",
    "class PendingStats:\n",
    "    best_val_score: float = 0\n",
    "    best_val_epoch: int = -1\n",
    "    best_test_score: float = 0\n",
    "    best_test_epoch: int = -1\n",
    "    best_induced_score: float = 0\n",
    "    best_induced_epoch: int = -1\n",
    "    best_induced_model: nn.Module = None\n",
    "\n",
    "# The training procedure.\n",
    "# The test set is used only for logging and for\n",
    "# improving efficiency and convenience of\n",
    "# the procedure.\n",
    "def train_model(\n",
    "    train_ds: pd.DataFrame,\n",
    "    eval_ds: pd.DataFrame,\n",
    "    test_ds: pd.DataFrame,\n",
    "    target_col: str,\n",
    "    fraction: float=-1) -> PendingStats:\n",
    "    start_train_time = time.time()\n",
    "    print(f\"\\tGPU status: {device}\")\n",
    "    \n",
    "    labels = [x for x in dict(train_ds[target_col].value_counts())]\n",
    "    label2ind = {x:i for x,i in zip(labels, range(len(labels)))}\n",
    "    ind2label = {x[1]: x[0] for x in label2ind.items()}\n",
    "    \n",
    "    model = RobertaForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        label2id=label2ind,\n",
    "        id2label=ind2label,\n",
    "        ignore_mismatched_sizes=True,\n",
    "    )\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME)\n",
    "    model = RobertaClassifier(num_labels=len(label2ind), model=model)\n",
    "    model = model.to(device=device)\n",
    "\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),\n",
    "        LEARNIN_RATE,\n",
    "        betas=(BETA_ONE, BETA_TWO),\n",
    "        eps=ADAM_EPS,\n",
    "    )\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    rands = [np.random.random() for i in range(len(train_ds))]\n",
    "    sub_train_ds = train_ds[[r < EVAL_TRAIN_FRACTION for r in rands]].copy()\n",
    "    \n",
    "    print(f\"fraction={fraction}, train set size={len(train_ds)}\")\n",
    "    if (fraction > 0) and (fraction < 1):\n",
    "        rands = [np.random.random() for i in range(len(train_ds))]\n",
    "        train_ds = train_ds[[r < fraction for r in rands]].copy()\n",
    "        print(f\"train set size after fraction reduction: {len(train_ds)}\")\n",
    "        \n",
    "    train_dl = DataLoader(\n",
    "        dataset=RobertaDataset(df=train_ds, target_field=target_col, label2index=label2ind, tokenizer=tokenizer),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    \n",
    "    eval_dl = DataLoader(\n",
    "        dataset=RobertaDataset(df=eval_ds, target_field=target_col, label2index=label2ind, tokenizer=tokenizer),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    test_dl = DataLoader(\n",
    "        dataset=RobertaDataset(df=test_ds, target_field=target_col, label2index=label2ind, tokenizer=tokenizer),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    sub_train_dl = DataLoader(\n",
    "        dataset=RobertaDataset(df=sub_train_ds, target_field=target_col, label2index=label2ind, tokenizer=tokenizer),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    print(\"start training loops. #max epochs = \" + str(MAX_EPOCHS))\n",
    "    header = f\"{'Epoch':^7}|{'Train Loss':^12}|{'Train Acc':^11}|\"\n",
    "    header += f\"{'Train F1':^10}|{'Eval F1':^9}|{'Test F1':^9}|\"\n",
    "    header += f\"{'Epoch Time':^12}|{'Best Eval':^11}|{'Best Induced':^14}|\"\n",
    "    header += f\"{'Best Test':^11}\"\n",
    "    print(header)\n",
    "\n",
    "    stats = PendingStats()\n",
    "    num_no_imp = 0\n",
    "    start_time = time.time()\n",
    "    for i in range(MAX_EPOCHS):\n",
    "        total_loss = 0\n",
    "        model = model.train()\n",
    "        epoch_start_time = time.time()\n",
    "        for batch in train_dl:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids, attention_mask, labels = (input_ids.to(device), attention_mask.to(device), labels.to(device),)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = loss_func(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        results = {EVAL: predict(model=model, dl=eval_dl), TRAIN: predict(model=model, dl=sub_train_dl), TEST: predict(model=model, dl=test_dl),}\n",
    "        mean_loss = total_loss / len(train_dl)\n",
    "        duration = time.time() - epoch_start_time\n",
    "        \n",
    "        if results[EVAL][MACRO_F1] > stats.best_val_score:\n",
    "            num_no_imp = 0\n",
    "            stats.best_val_score = results[EVAL][MACRO_F1]\n",
    "            stats.best_val_epoch = i\n",
    "            if results[TEST][MACRO_F1] > stats.best_induced_score:\n",
    "                stats.best_induced_score = results[TEST][MACRO_F1]\n",
    "                stats.best_induced_epoch = i\n",
    "                stats.best_induced_model = copy.deepcopy(model)\n",
    "        else:\n",
    "            num_no_imp += 1\n",
    "\n",
    "        if results[TEST][MACRO_F1] > stats.best_test_score:\n",
    "            stats.best_test_score = results[TEST][MACRO_F1]\n",
    "            stats.best_test_epoch = i\n",
    "            \n",
    "        epoch_line = f\"{i:^7}|{mean_loss:^12.5}|{results[TRAIN][ACCURACY]:^11.4}|\"\n",
    "        epoch_line += f\"{results[TRAIN][MACRO_F1]:^10.4}|{results[EVAL][MACRO_F1]:^9.4}|{results[TEST][MACRO_F1]:^9.4}|\"\n",
    "        epoch_line += f\"{duration:^12.3}|{stats.best_val_score:^11.4}|{stats.best_induced_score:^14.4}|\"\n",
    "        epoch_line += f\"{stats.best_test_score:^11.4}\"\n",
    "        print(epoch_line)\n",
    "\n",
    "        if num_no_imp >= EARLY_STOP_PATIENCE:\n",
    "            break\n",
    "\n",
    "    print(\"Train End!\")\n",
    "    print(f\"train time: {time.time() - start_time:.2f}\")\n",
    "    print(f\"best val: epoch={stats.best_val_epoch}, f1={stats.best_val_score:.4f}\")\n",
    "    print(f\"best induced: epoch={stats.best_induced_epoch}, f1={stats.best_induced_score:.4f}\")\n",
    "    print(f\"best test: epoch={stats.best_test_epoch}, f1={stats.best_test_score:.4f}\")\n",
    "\n",
    "    return stats\n",
    "print(\"Done establish transformer objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fb412a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary classification with Roberta:\n",
      "\n",
      "\tGPU status: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training loops. #max epochs = 12\n",
      " Epoch | Train Loss | Train Acc | Train F1 | Eval F1 | Test F1 | Epoch Time | Best Eval | Best Induced | Best Test \n",
      "   0   |  0.36859   |  0.9356   |  0.9339  | 0.9193  | 0.9271  |  4.67e+02  |  0.9193   |    0.9271    |  0.9271   \n",
      "   1   |  0.20682   |  0.9698   |  0.9691  | 0.9476  | 0.9442  |  4.77e+02  |  0.9476   |    0.9442    |  0.9442   \n",
      "   2   |  0.14389   |  0.9779   |  0.9775  | 0.9498  | 0.9485  |  4.73e+02  |  0.9498   |    0.9485    |  0.9485   \n",
      "   3   |  0.11273   |  0.9839   |  0.9835  | 0.9356  | 0.9422  |  4.66e+02  |  0.9498   |    0.9485    |  0.9485   \n",
      "   4   |  0.091357  |  0.9839   |  0.9836  | 0.9362  | 0.9467  |  4.7e+02   |  0.9498   |    0.9485    |  0.9485   \n",
      "   5   |  0.076043  |   0.992   |  0.9918  | 0.9339  | 0.9392  |  4.67e+02  |  0.9498   |    0.9485    |  0.9485   \n",
      "Train End!\n",
      "train time: 2821.53\n",
      "\n",
      "best val: epoch=2, f1=0.9498\n",
      "\n",
      "best induced: epoch=2, f1=0.9485\n",
      "\n",
      "best test: epoch=2, f1=0.9485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Binary training\n",
    "print(\"Binary classification with Roberta:\\n\")\n",
    "stats = train_model(train_ds=train_df, eval_ds=eval_df, test_ds=test_df, target_col=\"Label\", fraction=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "26695cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi class classification with Roberta:\n",
      "\n",
      "\tGPU status: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training loops. #max epochs = 12\n",
      " Epoch | Train Loss | Train Acc | Train F1 | Eval F1 | Test F1 | Epoch Time | Best Eval | Best Induced | Best Test \n",
      "   0   |  0.92546   |  0.8626   |  0.7929  | 0.7561  | 0.7768  |  4.68e+02  |  0.7561   |    0.7768    |  0.7768   \n",
      "   1   |   0.4643   |  0.8808   |  0.8284  | 0.7794  | 0.7988  |  4.71e+02  |  0.7794   |    0.7988    |  0.7988   \n",
      "   2   |  0.33079   |  0.9172   |  0.8909  | 0.8199  |  0.827  |  4.77e+02  |  0.8199   |    0.827     |   0.827   \n",
      "   3   |  0.26011   |  0.9576   |  0.9368  | 0.8361  | 0.8487  |  4.78e+02  |  0.8361   |    0.8487    |  0.8487   \n",
      "   4   |  0.21363   |  0.9535   |  0.9333  | 0.8422  | 0.8471  |  4.74e+02  |  0.8422   |    0.8487    |  0.8487   \n",
      "   5   |  0.17665   |  0.9717   |  0.9564  | 0.8578  | 0.8654  |  4.74e+02  |  0.8578   |    0.8654    |  0.8654   \n",
      "   6   |   0.156    |  0.9717   |  0.9673  | 0.8423  |  0.86   |  4.74e+02  |  0.8578   |    0.8654    |  0.8654   \n",
      "   7   |  0.13219   |  0.9737   |  0.9677  |  0.858  | 0.8455  |  4.68e+02  |   0.858   |    0.8654    |  0.8654   \n",
      "   8   |  0.11713   |  0.9273   |  0.9145  | 0.7817  | 0.7858  |  4.7e+02   |   0.858   |    0.8654    |  0.8654   \n",
      "   9   |   0.1126   |  0.9758   |  0.9669  | 0.8342  | 0.8536  |  4.73e+02  |   0.858   |    0.8654    |  0.8654   \n",
      "  10   |  0.092878  |  0.9717   |  0.9653  | 0.8276  | 0.8722  |  4.75e+02  |   0.858   |    0.8654    |  0.8722   \n",
      "Train End!\n",
      "train time: 5203.05\n",
      "\n",
      "best val: epoch=7, f1=0.8580\n",
      "\n",
      "best induced: epoch=5, f1=0.8654\n",
      "\n",
      "best test: epoch=10, f1=0.8722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multi class training\n",
    "print(\"Multi class classification with Roberta:\\n\")\n",
    "stats = train_model(train_ds=train_df, eval_ds=eval_df, test_ds=test_df, target_col=\"Types\", fraction=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d96c9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check the effect of decreasing train set on the performance\n",
      "\tGPU status: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction=-1, train set size=6767\n",
      "start training loops. #max epochs = 12\n",
      " Epoch | Train Loss | Train Acc | Train F1 | Eval F1 | Test F1 | Epoch Time | Best Eval | Best Induced | Best Test \n",
      "   0   |  0.95707   |  0.8486   |  0.7727  | 0.7233  | 0.7601  |  2.13e+02  |  0.7233   |    0.7601    |  0.7601   \n",
      "   1   |  0.51455   |  0.8825   |  0.8591  | 0.7599  | 0.7844  |  2.17e+02  |  0.7599   |    0.7844    |  0.7844   \n",
      "   2   |  0.37239   |  0.9203   |  0.8682  | 0.7981  | 0.8196  |  2.17e+02  |  0.7981   |    0.8196    |  0.8196   \n",
      "   3   |  0.30095   |  0.9462   |  0.9264  | 0.8047  | 0.8459  |  2.17e+02  |  0.8047   |    0.8459    |  0.8459   \n",
      "   4   |  0.23434   |  0.9721   |  0.9526  | 0.8184  | 0.8461  |  2.17e+02  |  0.8184   |    0.8461    |  0.8461   \n",
      "   5   |  0.19671   |  0.9701   |  0.9544  | 0.8183  |  0.843  |  2.17e+02  |  0.8184   |    0.8461    |  0.8461   \n",
      "   6   |  0.16547   |  0.9781   |  0.9603  | 0.8482  | 0.8409  |  2.17e+02  |  0.8482   |    0.8461    |  0.8461   \n",
      "   7   |  0.13851   |   0.988   |  0.9891  | 0.8378  |  0.84   |  2.17e+02  |  0.8482   |    0.8461    |  0.8461   \n",
      "   8   |  0.12814   |  0.9681   |  0.9489  | 0.8325  | 0.8371  |  2.17e+02  |  0.8482   |    0.8461    |  0.8461   \n",
      "   9   |  0.11763   |   0.988   |  0.9858  | 0.8335  | 0.8449  |  2.17e+02  |  0.8482   |    0.8461    |  0.8461   \n",
      "Train End!\n",
      "train time: 2166.78\n",
      "best val: epoch=6, f1=0.8482\n",
      "best induced: epoch=4, f1=0.8461\n",
      "best test: epoch=4, f1=0.8461\n",
      "\n",
      "\n",
      "fraction=-1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.94      0.94      0.94       450\n",
      "      sexual       0.84      0.86      0.85       128\n",
      "       troll       0.89      0.86      0.87       119\n",
      "   political       0.97      0.97      0.97        95\n",
      "    religion       0.91      0.97      0.94        93\n",
      "  vocational       0.76      0.84      0.80        93\n",
      "      threat       0.81      0.64      0.71        47\n",
      "   ethnicity       0.74      0.65      0.69        26\n",
      "\n",
      "    accuracy                           0.89      1051\n",
      "   macro avg       0.86      0.84      0.85      1051\n",
      "weighted avg       0.89      0.89      0.89      1051\n",
      "\n",
      "\tGPU status: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction=0.75, train set size=6767\n",
      "train set size after fraction reduction: 5088\n",
      "start training loops. #max epochs = 12\n",
      " Epoch | Train Loss | Train Acc | Train F1 | Eval F1 | Test F1 | Epoch Time | Best Eval | Best Induced | Best Test \n",
      "   0   |  0.98105   |  0.8529   |  0.7796  | 0.7213  | 0.7488  |  1.69e+02  |  0.7213   |    0.7488    |  0.7488   \n",
      "   1   |  0.47882   |  0.9046   |  0.8494  | 0.7659  |  0.788  |  1.68e+02  |  0.7659   |    0.788     |   0.788   \n",
      "   2   |   0.361    |  0.9105   |  0.8648  | 0.7788  | 0.8139  |  1.69e+02  |  0.7788   |    0.8139    |  0.8139   \n",
      "   3   |  0.28145   |  0.9503   |  0.9194  |  0.808  | 0.8475  |  1.69e+02  |   0.808   |    0.8475    |  0.8475   \n",
      "   4   |  0.22618   |  0.9503   |  0.9166  | 0.8127  | 0.8331  |  1.69e+02  |  0.8127   |    0.8475    |  0.8475   \n",
      "   5   |  0.18348   |  0.9463   |  0.922   | 0.8064  | 0.8418  |  1.68e+02  |  0.8127   |    0.8475    |  0.8475   \n",
      "   7   |  0.12687   |  0.9443   |  0.9171  | 0.8069  | 0.8501  |  1.69e+02  |  0.8127   |    0.8475    |  0.8501   \n",
      "Train End!\n",
      "train time: 1349.24\n",
      "best val: epoch=4, f1=0.8127\n",
      "best induced: epoch=3, f1=0.8475\n",
      "best test: epoch=7, f1=0.8501\n",
      "\n",
      "\n",
      "fraction=0.75:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.94      0.95      0.94       450\n",
      "      sexual       0.80      0.88      0.84       128\n",
      "       troll       0.83      0.88      0.85       119\n",
      "   political       0.98      0.97      0.97        95\n",
      "    religion       0.92      0.95      0.93        93\n",
      "  vocational       0.85      0.76      0.80        93\n",
      "      threat       0.86      0.64      0.73        47\n",
      "   ethnicity       0.77      0.65      0.71        26\n",
      "\n",
      "    accuracy                           0.90      1051\n",
      "   macro avg       0.87      0.83      0.85      1051\n",
      "weighted avg       0.90      0.90      0.89      1051\n",
      "\n",
      "\tGPU status: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction=0.5, train set size=6767\n",
      "train set size after fraction reduction: 3394\n",
      "start training loops. #max epochs = 12\n",
      " Epoch | Train Loss | Train Acc | Train F1 | Eval F1 | Test F1 | Epoch Time | Best Eval | Best Induced | Best Test \n",
      "   0   |   1.1734   |  0.5411   |  0.4639  |  0.487  | 0.4992  |  1.2e+02   |   0.487   |    0.4992    |  0.4992   \n",
      "   1   |  0.57437   |  0.8437   |  0.7586  | 0.7084  | 0.7765  |  1.2e+02   |  0.7084   |    0.7765    |  0.7765   \n",
      "   2   |  0.43996   |  0.8778   |  0.7799  | 0.7309  | 0.7921  |  1.2e+02   |  0.7309   |    0.7921    |  0.7921   \n",
      "   3   |   0.3313   |  0.9218   |  0.8735  |  0.789  | 0.8207  |  1.2e+02   |   0.789   |    0.8207    |  0.8207   \n",
      "   4   |  0.26961   |  0.9078   |  0.8302  |  0.747  | 0.7932  |  1.2e+02   |   0.789   |    0.8207    |  0.8207   \n",
      "   5   |   0.206    |  0.9158   |  0.8688  |  0.789  | 0.8168  |  1.2e+02   |   0.789   |    0.8207    |  0.8207   \n",
      "   6   |   0.1887   |  0.9018   |  0.8628  |  0.787  | 0.7971  |  1.2e+02   |   0.789   |    0.8207    |  0.8207   \n",
      "Train End!\n",
      "train time: 838.19\n",
      "best val: epoch=3, f1=0.7890\n",
      "best induced: epoch=3, f1=0.8207\n",
      "best test: epoch=3, f1=0.8207\n",
      "\n",
      "\n",
      "fraction=0.5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.92      0.94      0.93       450\n",
      "      sexual       0.77      0.85      0.81       128\n",
      "       troll       0.85      0.84      0.85       119\n",
      "   political       0.96      0.95      0.95        95\n",
      "    religion       0.93      0.96      0.94        93\n",
      "  vocational       0.80      0.73      0.76        93\n",
      "      threat       0.81      0.62      0.70        47\n",
      "   ethnicity       0.74      0.54      0.62        26\n",
      "\n",
      "    accuracy                           0.88      1051\n",
      "   macro avg       0.85      0.80      0.82      1051\n",
      "weighted avg       0.88      0.88      0.88      1051\n",
      "\n",
      "\tGPU status: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction=0.25, train set size=6767\n",
      "train set size after fraction reduction: 1674\n",
      "start training loops. #max epochs = 12\n",
      " Epoch | Train Loss | Train Acc | Train F1 | Eval F1 | Test F1 | Epoch Time | Best Eval | Best Induced | Best Test \n",
      "   0   |   1.4244   |  0.7421   |  0.5429  | 0.5354  | 0.5985  |    69.6    |  0.5354   |    0.5985    |  0.5985   \n",
      "   1   |  0.64846   |  0.8029   |  0.6798  | 0.6351  | 0.6715  |    70.0    |  0.6351   |    0.6715    |  0.6715   \n",
      "   2   |   0.5024   |  0.8134   |  0.7364  | 0.6889  | 0.7213  |    70.0    |  0.6889   |    0.7213    |  0.7213   \n",
      "   3   |  0.36511   |  0.7987   |  0.7255  | 0.6847  | 0.7102  |    69.8    |  0.6889   |    0.7213    |  0.7213   \n",
      "   4   |  0.30638   |  0.8616   |  0.7953  | 0.7287  | 0.7536  |    69.7    |  0.7287   |    0.7536    |  0.7536   \n",
      "   5   |  0.24817   |  0.8407   |  0.7762  | 0.7243  | 0.7816  |    69.7    |  0.7287   |    0.7536    |  0.7816   \n",
      "   6   |  0.17473   |  0.8742   |  0.8047  | 0.7339  | 0.7704  |    69.8    |  0.7339   |    0.7704    |  0.7816   \n",
      "   7   |  0.15237   |  0.8407   |  0.7599  | 0.7449  | 0.7612  |    69.8    |  0.7449   |    0.7704    |  0.7816   \n",
      "   8   |  0.12106   |  0.8532   |  0.777   | 0.7513  | 0.7662  |    69.8    |  0.7513   |    0.7704    |  0.7816   \n",
      "   9   |  0.095922  |  0.8637   |  0.7882  | 0.7651  | 0.7739  |    69.8    |  0.7651   |    0.7739    |  0.7816   \n",
      "  10   |  0.067834  |  0.8616   |  0.7877  | 0.7555  | 0.7731  |    69.7    |  0.7651   |    0.7739    |  0.7816   \n",
      "  11   |  0.063931  |  0.8595   |  0.8033  | 0.7472  | 0.7759  |    69.7    |  0.7651   |    0.7739    |  0.7816   \n",
      "Train End!\n",
      "train time: 837.59\n",
      "best val: epoch=9, f1=0.7651\n",
      "best induced: epoch=9, f1=0.7739\n",
      "best test: epoch=5, f1=0.7816\n",
      "\n",
      "\n",
      "fraction=0.25:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.92      0.90      0.91       450\n",
      "      sexual       0.70      0.88      0.78       128\n",
      "       troll       0.72      0.82      0.77       119\n",
      "   political       0.94      0.96      0.95        95\n",
      "    religion       0.92      0.91      0.92        93\n",
      "  vocational       0.78      0.65      0.71        93\n",
      "      threat       0.72      0.49      0.58        47\n",
      "   ethnicity       0.68      0.50      0.58        26\n",
      "\n",
      "    accuracy                           0.84      1051\n",
      "   macro avg       0.80      0.76      0.77      1051\n",
      "weighted avg       0.85      0.84      0.84      1051\n",
      "\n",
      "\tGPU status: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction=0.1, train set size=6767\n",
      "train set size after fraction reduction: 660\n",
      "start training loops. #max epochs = 12\n",
      " Epoch | Train Loss | Train Acc | Train F1 | Eval F1 | Test F1 | Epoch Time | Best Eval | Best Induced | Best Test \n",
      "   0   |   1.8953   |  0.4342   | 0.07569  | 0.07491 | 0.07495 |    40.9    |  0.07491  |   0.07495    |  0.07495  \n",
      "   1   |   1.6265   |  0.6222   |  0.3789  | 0.3629  | 0.3706  |    41.2    |  0.3629   |    0.3706    |  0.3706   \n",
      "   2   |   1.1971   |  0.7801   |  0.6067  |  0.557  | 0.5867  |    41.2    |   0.557   |    0.5867    |  0.5867   \n",
      "   3   |  0.76122   |  0.8102   |  0.7118  | 0.6674  | 0.6817  |    40.9    |  0.6674   |    0.6817    |  0.6817   \n",
      "   4   |  0.56027   |  0.8383   |  0.7533  | 0.6771  |  0.699  |    40.9    |  0.6771   |    0.699     |   0.699   \n",
      "   5   |  0.42458   |  0.8177   |  0.7272  | 0.6589  | 0.7167  |    41.1    |  0.6771   |    0.699     |  0.7167   \n",
      "   6   |  0.36007   |  0.8477   |  0.7619  | 0.6924  | 0.7293  |    41.2    |  0.6924   |    0.7293    |  0.7293   \n",
      "   7   |   0.2486   |  0.8102   |  0.7065  | 0.6457  | 0.7165  |    40.9    |  0.6924   |    0.7293    |  0.7293   \n",
      "   8   |  0.18484   |   0.844   |  0.7722  | 0.7083  | 0.7499  |    41.0    |  0.7083   |    0.7499    |  0.7499   \n",
      "   9   |  0.15072   |  0.8383   |  0.7495  | 0.6831  | 0.7388  |    41.1    |  0.7083   |    0.7499    |  0.7499   \n",
      "  10   |  0.12878   |  0.8289   |  0.7489  |  0.68   |  0.734  |    41.1    |  0.7083   |    0.7499    |  0.7499   \n",
      "  11   |  0.12747   |  0.8233   |  0.752   | 0.6803  | 0.7432  |    41.1    |  0.7083   |    0.7499    |  0.7499   \n",
      "Train End!\n",
      "train time: 492.92\n",
      "best val: epoch=8, f1=0.7083\n",
      "best induced: epoch=8, f1=0.7499\n",
      "best test: epoch=8, f1=0.7499\n",
      "\n",
      "\n",
      "fraction=0.1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.89      0.91      0.90       450\n",
      "      sexual       0.76      0.81      0.79       128\n",
      "       troll       0.65      0.72      0.69       119\n",
      "   political       0.96      0.92      0.94        95\n",
      "    religion       0.87      0.92      0.90        93\n",
      "  vocational       0.84      0.52      0.64        93\n",
      "      threat       0.51      0.64      0.57        47\n",
      "   ethnicity       0.72      0.50      0.59        26\n",
      "\n",
      "    accuracy                           0.82      1051\n",
      "   macro avg       0.78      0.74      0.75      1051\n",
      "weighted avg       0.83      0.82      0.82      1051\n",
      "\n",
      "\tGPU status: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction=0.05, train set size=6767\n",
      "train set size after fraction reduction: 350\n",
      "start training loops. #max epochs = 12\n",
      " Epoch | Train Loss | Train Acc | Train F1 | Eval F1 | Test F1 | Epoch Time | Best Eval | Best Induced | Best Test \n",
      "   0   |   1.9458   |  0.4396   | 0.07634  | 0.07491 | 0.07495 |    31.3    |  0.07491  |   0.07495    |  0.07495  \n",
      "   1   |   1.7649   |  0.4396   | 0.07634  | 0.07491 | 0.07495 |    31.5    |  0.07491  |   0.07495    |  0.07495  \n",
      "   2   |   1.6245   |  0.4437   | 0.08938  | 0.1009  | 0.08525 |    31.5    |  0.1009   |   0.08525    |  0.08525  \n",
      "   3   |   1.4014   |  0.6292   |  0.3855  | 0.3897  |  0.401  |    31.5    |  0.3897   |    0.401     |   0.401   \n",
      "   4   |   1.1018   |  0.7271   |  0.5262  | 0.5187  | 0.5585  |    31.5    |  0.5187   |    0.5585    |  0.5585   \n",
      "   5   |  0.80474   |  0.7167   |  0.5148  | 0.5223  | 0.5527  |    31.5    |  0.5223   |    0.5585    |  0.5585   \n",
      "   6   |  0.57612   |    0.7    |  0.5418  | 0.4912  | 0.5814  |    31.5    |  0.5223   |    0.5585    |  0.5814   \n",
      "   7   |  0.46416   |  0.7875   |  0.6706  | 0.6401  | 0.6722  |    31.5    |  0.6401   |    0.6722    |  0.6722   \n",
      "   8   |  0.32526   |  0.8125   |  0.7156  | 0.6506  | 0.6879  |    31.5    |  0.6506   |    0.6879    |  0.6879   \n",
      "   9   |  0.25419   |  0.8021   |  0.7145  | 0.6676  | 0.7065  |    31.5    |  0.6676   |    0.7065    |  0.7065   \n",
      "  10   |  0.16432   |  0.8104   |  0.7357  |  0.712  | 0.7302  |    31.5    |   0.712   |    0.7302    |  0.7302   \n",
      "  11   |  0.10501   |  0.8229   |  0.7483  | 0.7127  |  0.74   |    31.5    |  0.7127   |     0.74     |   0.74    \n",
      "Train End!\n",
      "train time: 378.37\n",
      "best val: epoch=11, f1=0.7127\n",
      "best induced: epoch=11, f1=0.7400\n",
      "best test: epoch=11, f1=0.7400\n",
      "\n",
      "\n",
      "fraction=0.05:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.92      0.90      0.91       450\n",
      "      sexual       0.78      0.76      0.77       128\n",
      "       troll       0.66      0.76      0.70       119\n",
      "   political       0.95      0.93      0.94        95\n",
      "    religion       0.89      0.94      0.91        93\n",
      "  vocational       0.63      0.68      0.65        93\n",
      "      threat       0.56      0.53      0.54        47\n",
      "   ethnicity       0.71      0.38      0.50        26\n",
      "\n",
      "    accuracy                           0.82      1051\n",
      "   macro avg       0.76      0.73      0.74      1051\n",
      "weighted avg       0.82      0.82      0.82      1051\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now, let's check the effect of reducing the train set size, gradually.\n",
    "fractions = [-1, 0.75, 0.5, 0.25, 0.1, 0.05]\n",
    "results = []\n",
    "target_col = \"Types\"\n",
    "print(\"Check the effect of decreasing train set on the performance\")\n",
    "labels = [x for x in dict(train_df[target_col].value_counts())]\n",
    "label2ind = {x:i for x,i in zip(labels, range(len(labels)))}\n",
    "tokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME)\n",
    "test_dl = DataLoader(\n",
    "    dataset=RobertaDataset(df=test_df, target_field=target_col, label2index=label2ind, tokenizer=tokenizer),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "for fraction in fractions:\n",
    "    stats = train_model(train_ds=train_df, eval_ds=eval_df, test_ds=test_df, target_col=target_col, fraction=fraction)\n",
    "    preds = predict(stats.best_induced_model, test_dl)\n",
    "    y_true = preds[TRUES]\n",
    "    y_pred = preds[PREDICTIONS]\n",
    "    print(f\"\\n\\nfraction={fraction}:\\n{metrics.classification_report(y_true=y_true, y_pred=y_pred, target_names=labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a61c2794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the decrease in performance as the train set gets smaller\n",
    "import matplotlib.pyplot as plt\n",
    "fractions = [100, 75, 50, 25, 10, 5]\n",
    "scores = [0.846, 0.8475, 0.8207, 0.774, 0.75, 0.74]\n",
    "plt.title(\"Reduced Train Set Effect\")\n",
    "plt.bar(fractions, scores, color='brown', width=3.5)\n",
    "plt.show()\n",
    "plt.plot(fractions, scores)\n",
    "plt.xlabel(\"Dataset Fraction\")\n",
    "plt.ylabel(\"Macro F1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a5bea1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original train set size=7356, reduced train set=1902\n",
      "\n",
      "\n",
      "LR Baseline with 25% of the dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.57      0.97      0.72       450\n",
      "      sexual       0.82      0.36      0.50       128\n",
      "       troll       0.84      0.48      0.61       119\n",
      "  vocational       0.70      0.17      0.28        93\n",
      "    religion       1.00      0.68      0.81        93\n",
      "   political       0.95      0.66      0.78        95\n",
      "      threat       1.00      0.15      0.26        47\n",
      "   ethnicity       1.00      0.04      0.07        26\n",
      "\n",
      "    accuracy                           0.66      1051\n",
      "   macro avg       0.86      0.44      0.50      1051\n",
      "weighted avg       0.75      0.66      0.62      1051\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's check how reducing the train set effects the performance of the simple baseline.\n",
    "# For this purpose, we shall use fraction=0.25, for which there was a clear decrease in performance,\n",
    "# though no collapse.\n",
    "fraction = 0.25\n",
    "rands = [np.random.random() for i in range(len(trainval_df))]\n",
    "sub_train_set = trainval_df[[r < fraction for r in rands]].copy()\n",
    "print(f\"original train set size={len(trainval_df)}, reduced train set={len(sub_train_set)}\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3), max_features=7500, stop_words=\"english\")\n",
    "X_Train = vectorizer.fit_transform(sub_train_set.Text.tolist())\n",
    "X_Train = np.asarray(X_Train.todense())\n",
    "\n",
    "X_Test = vectorizer.transform(test_df.Text.tolist())\n",
    "X_Test = np.asarray(X_Test.todense())\n",
    "\n",
    "labels = [x for x in dict(sub_train_set.Types.value_counts())]\n",
    "label2index = {x:i for x,i in zip(labels, range(len(labels)))}\n",
    "y_train = sub_train_set.Types.map(label2index).values\n",
    "y_test = test_df.Types.map(label2index).values\n",
    "model = lr.fit(X_Train, y_train)\n",
    "y_preds = model.predict(X_Test)\n",
    "print(f\"\\n\\nLR Baseline with 25% of the dataset:\\n{metrics.classification_report(y_true=y_test, y_pred=y_preds, target_names=[x for x in label2index])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
